{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import torch.optim as optim\n",
    "\n",
    "import os\n",
    "from PIL import Image\n",
    "import argparse\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, root, transform=None):\n",
    "        self.root = root\n",
    "        self.transform = transform\n",
    "        self.classes = os.listdir(root)\n",
    "        self.class_to_idx = {c: int(c) for i, c in enumerate(self.classes)}\n",
    "        self.imgs = []\n",
    "        for c in self.classes:\n",
    "            class_dir = os.path.join(root, c)\n",
    "            for filename in os.listdir(class_dir):\n",
    "                path = os.path.join(class_dir, filename)\n",
    "                self.imgs.append((path, self.class_to_idx[c])) \n",
    "    def __len__(self):\n",
    "        return len(self.imgs)\n",
    "    def __getitem__(self, index):\n",
    "        path, target = self.imgs[index]\n",
    "        img = Image.open(path).convert('RGB')\n",
    "        if self.transform is not None:\n",
    "            img = self.transform(img)\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################\n",
    "#If you want to use your own custom model\n",
    "#Write your code here\n",
    "####################\n",
    "class Custom_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Custom_model, self).__init__()\n",
    "        #place your layers\n",
    "        #CNN, MLP and etc.\n",
    "\n",
    "    def forward(self, input):\n",
    "        #place for your model\n",
    "        #Input: 3* Width * Height\n",
    "        #Output: Probability of 50 class label\n",
    "        return predicted_label\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Identity(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Identity, self).__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "####################\n",
    "#Modify your code here\n",
    "####################\n",
    "def model_selection(selection):\n",
    "    if selection == \"resnet\":\n",
    "        model = models.resnet18()\n",
    "        model.conv1 =  nn.Conv2d(3, 64, kernel_size=3,stride=1, padding=1, bias=False)\n",
    "        model.layer4 = Identity()\n",
    "        model.fc = nn.Linear(256, 50)\n",
    "    elif selection == \"vgg\":\n",
    "        model = models.vgg11_bn()\n",
    "        model.features = nn.Sequential(*list(model.features.children())[:-7])\n",
    "        model.classifier = nn.Sequential( nn.Linear(in_features=25088, out_features=50, bias=True))\n",
    "    elif selection == \"mobilenet\":\n",
    "        model = models.mobilenet_v2()\n",
    "        model.classifier = nn.Sequential(nn.Linear(in_features=1280, out_features=50, bias=True))\n",
    "    elif  selection =='custom':\n",
    "        model = Custom_model()\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net1, labeled_loader, optimizer, criterion):\n",
    "    net1.train()\n",
    "    #Supervised_training\n",
    "    for batch_idx, (inputs, targets) in enumerate(labeled_loader):\n",
    "        if torch.cuda.is_available():\n",
    "            inputs, targets = inputs.cuda(), targets.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        ####################\n",
    "        #Write your Code\n",
    "        #Model should be optimized based on given \"targets\"\n",
    "        ####################\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(net, testloader):\n",
    "    net.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (inputs, targets) in enumerate(testloader):\n",
    "            if torch.cuda.is_available():\n",
    "                inputs, targets = inputs.cuda(), targets.cuda()\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += targets.size(0)\n",
    "            correct += predicted.eq(targets).sum().item()\n",
    "        return 100. * correct / total\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if __name__ == \"__main__\":\n",
    "\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument('--test',  type=str,  default='False')\n",
    "    parser.add_argument('--student_abs_path',  type=str,  default='./')\n",
    "    args = parser.parse_args()\n",
    "\n",
    "\n",
    "\n",
    "    if not os.path.exists(os.path.join(args.student_abs_path, 'logs', 'Supervised_Learning')):\n",
    "        os.makedirs(os.path.join(args.student_abs_path, 'logs', 'Supervised_Learning'))\n",
    "\n",
    "\n",
    "\n",
    "    batch_size = #Input the number of batch size\n",
    "    if args.test == 'False':\n",
    "        train_transform = transforms.Compose([\n",
    "                    transforms.RandomResizedCrop(64, scale=(0.2, 1.0)),\n",
    "                    transforms.RandomHorizontalFlip(),\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "        test_transform = transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "                ])\n",
    "        \n",
    "        dataset = CustomDataset(root = './data/Supervised_Learning/labeled', transform = train_transform)\n",
    "        labeled_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, num_workers=4, pin_memory=True)\n",
    "        \n",
    "        dataset = CustomDataset(root = './data/Supervised_Learning/val', transform = test_transform)\n",
    "        val_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "    else :\n",
    "        test_transform = transforms.Compose([\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        \n",
    "\n",
    "    model_name = #Input model name to use in the model_section class\n",
    "                 #e.g., 'resnet', 'vgg', 'mobilenet', 'custom'\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model = model_selection(model_name).cuda()\n",
    "    else :\n",
    "        model = model_selection(model_name)\n",
    "\n",
    "    params = sum(p.numel() for p in model.parameters() if p.requires_grad) / 1e6\n",
    "\n",
    "    #You may want to write a loader code that loads the model state to continue the learning process\n",
    "    #Since this learning process may take a while.\n",
    "    \n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        criterion = nn.CrossEntropyLoss().cuda()\n",
    "    else :\n",
    "        criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    epoch =  #Input the number of Epochs\n",
    "    optimizer = #Your optimizer here\n",
    "    #You may want to add a scheduler for your loss\n",
    "    \n",
    "    best_result = 0\n",
    "    if args.test == 'False':\n",
    "        assert params < 7.0, \"Exceed the limit on the number of model parameters\" \n",
    "        for e in range(0, epoch):\n",
    "            train(model, labeled_loader, optimizer, criterion)\n",
    "            tmp_res = test(model, val_loader)\n",
    "            # You can change the saving strategy, but you can't change the file name/path\n",
    "            # If there's any difference to the file name/path, it will not be evaluated.\n",
    "            print('{}th performance, res : {}'.format(e, tmp_res))\n",
    "            if best_result < tmp_res:\n",
    "                best_result = tmp_res\n",
    "                torch.save(model.state_dict(),  os.path.join('./logs', 'Supervised_Learning', 'best_model.pt'))\n",
    "        print('Final performance {} - {}', best_result, params)\n",
    "            \n",
    "            \n",
    "        \n",
    "    else:\n",
    "        #This part is used to evaluate. \n",
    "        #Do not edit this part!\n",
    "        dataset = CustomDataset(root = '/data/23_1_ML_challenge/Supervised_Learning/test', transform = test_transform)\n",
    "        test_loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=2, pin_memory=True)\n",
    "\n",
    "        model.load_state_dict(torch.load(os.path.join(args.student_abs_path, 'logs', 'Supervised_Learning', 'best_model.pt'), map_location=torch.device('cuda')))\n",
    "        res = test(model, test_loader)\n",
    "        print(res, ' - ' , params)\n",
    "    \n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
